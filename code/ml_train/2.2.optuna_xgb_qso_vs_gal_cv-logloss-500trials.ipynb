{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QSO VS GALAXY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T02:57:47.007873Z",
     "start_time": "2020-11-25T02:57:45.478960Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    f1_score, \n",
    "    accuracy_score, \n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    matthews_corrcoef,\n",
    "    )\n",
    "\n",
    "\n",
    "# def make_binary_classification_target(y, pos_label, verbose=False):\n",
    "#     '''Turn multi-class targets into binary classification targets.'''\n",
    "#     pos_idx = (y==pos_label)\n",
    "#     y[pos_idx] = 1\n",
    "#     y[~pos_idx] = 0\n",
    "#     if verbose:\n",
    "#         print ('Positive target:\\t{}'.format(pos_label))\n",
    "#         print ('Imbalance ratio:\\t{:.3f}'.format((y==0).sum()/(y==1).sum()))\n",
    "#     y = y.astype(int)\n",
    "#     return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T02:57:47.015355Z",
     "start_time": "2020-11-25T02:57:47.011164Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load QSO&GALAXY binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T02:57:49.173680Z",
     "start_time": "2020-11-25T02:57:48.770985Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(['QSO','GALAXY'])\n",
    "df = pd.read_csv('trainingset_binary2_test6.csv')\n",
    "features = ['iz','zy','yj','jh','hk','iw1','zw1','yw1','jw1','hw1','kw1','w1w2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 和test5一样，不用重新训练了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T02:57:50.360915Z",
     "start_time": "2020-11-25T02:57:49.946752Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df[features].values\n",
    "y = le.transform(df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T02:57:51.341896Z",
     "start_time": "2020-11-25T02:57:50.844701Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=8888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T02:57:51.707585Z",
     "start_time": "2020-11-25T02:57:51.699217Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186057, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186057,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((89336,), (96721,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[np.where(y_train==0)].shape, y_train[np.where(y_train==1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46515,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model using XGBoost CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T02:57:56.076573Z",
     "start_time": "2020-11-25T02:57:56.059328Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    param = {\n",
    "        'verbosity': 1,\n",
    "        'objective': 'binary:logistic',  # 注意objective不是multi\n",
    "        'booster': 'gbtree',\n",
    "        'tree_method': 'hist',\n",
    "        'lambda': trial.suggest_uniform('lambda', 0.5, 3.0),\n",
    "        'alpha': trial.suggest_uniform('alpha', 0, 2.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "        'eta': trial.suggest_categorical('eta', [0.01, 0.1, 0.2, 0.3]), #learning_rate\n",
    "        'gamma': trial.suggest_uniform('gamma', 0, 3.0), #min_split_loss\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.8, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.8, 1.0),\n",
    "        'max_delta_step': trial.suggest_int('max_delta_step', 1, 8)\n",
    "    }\n",
    "\n",
    "\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, 'test-logloss')\n",
    "    history = xgb.cv(\n",
    "        param,\n",
    "        dtrain,\n",
    "        num_boost_round=100,  # fixed,because the increasing num boost round can offset the decreasing eta.\n",
    "        nfold=5, \n",
    "        metrics=['logloss'],\n",
    "        early_stopping_rounds=10, \n",
    "        stratified=True, \n",
    "        seed=8888,\n",
    "        callbacks=[pruning_callback]\n",
    "    )\n",
    "    mean_logloss = history['test-logloss-mean'].values[-1]\n",
    "    return mean_logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T03:33:32.183248Z",
     "start_time": "2020-11-25T02:58:00.395333Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-02 22:01:12,259]\u001b[0m A new study created in memory with name: no-name-f1c77b5b-0058-4deb-b115-cb0ea4b662a8\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:01:29,954]\u001b[0m Trial 0 finished with value: 0.0428942 and parameters: {'lambda': 2.129022935164331, 'alpha': 0.7754099067961129, 'max_depth': 6, 'eta': 0.1, 'gamma': 0.838087354398074, 'grow_policy': 'lossguide', 'min_child_weight': 3, 'subsample': 0.9542725205803843, 'colsample_bytree': 0.8739444008169417, 'max_delta_step': 4}. Best is trial 0 with value: 0.0428942.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:01:54,790]\u001b[0m Trial 1 finished with value: 0.042928 and parameters: {'lambda': 1.5703247114048, 'alpha': 0.08856498335288654, 'max_depth': 8, 'eta': 0.2, 'gamma': 0.4903595064920122, 'grow_policy': 'lossguide', 'min_child_weight': 1, 'subsample': 0.9470349864875071, 'colsample_bytree': 0.8338554197250998, 'max_delta_step': 1}. Best is trial 0 with value: 0.0428942.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:02:19,945]\u001b[0m Trial 2 finished with value: 0.2342302 and parameters: {'lambda': 1.3955637723583467, 'alpha': 1.2486771723977204, 'max_depth': 7, 'eta': 0.01, 'gamma': 0.2580695680198697, 'grow_policy': 'lossguide', 'min_child_weight': 5, 'subsample': 0.977190473056871, 'colsample_bytree': 0.9025002820468669, 'max_delta_step': 3}. Best is trial 0 with value: 0.0428942.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:02:27,668]\u001b[0m Trial 3 finished with value: 0.0424108 and parameters: {'lambda': 1.2413359401393276, 'alpha': 0.16326090314688657, 'max_depth': 8, 'eta': 0.1, 'gamma': 1.1868232671204701, 'grow_policy': 'depthwise', 'min_child_weight': 4, 'subsample': 0.8780950055491423, 'colsample_bytree': 0.9241363413993084, 'max_delta_step': 3}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:02:37,807]\u001b[0m Trial 4 finished with value: 0.0433184 and parameters: {'lambda': 1.5285366354144707, 'alpha': 0.15809139694916796, 'max_depth': 8, 'eta': 0.3, 'gamma': 2.8852711509607696, 'grow_policy': 'lossguide', 'min_child_weight': 4, 'subsample': 0.9771746532262666, 'colsample_bytree': 0.8905288279476813, 'max_delta_step': 6}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:02:39,842]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:02:43,846]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:02:50,366]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:02:56,524]\u001b[0m Trial 8 finished with value: 0.0425658 and parameters: {'lambda': 2.728012402386946, 'alpha': 0.14109472066204032, 'max_depth': 9, 'eta': 0.2, 'gamma': 0.3938121085538545, 'grow_policy': 'depthwise', 'min_child_weight': 2, 'subsample': 0.8932210931673706, 'colsample_bytree': 0.8837081543340171, 'max_delta_step': 2}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:03:07,526]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 89.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:03:08,950]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:03:14,987]\u001b[0m Trial 11 finished with value: 0.0427928 and parameters: {'lambda': 2.7758079074403375, 'alpha': 0.44385937496683214, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.3866082061691727, 'grow_policy': 'depthwise', 'min_child_weight': 3, 'subsample': 0.840907807025788, 'colsample_bytree': 0.9387296280448322, 'max_delta_step': 2}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:03:18,606]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 37.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:03:21,898]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 32.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:03:23,753]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:03:25,770]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:03:31,482]\u001b[0m Trial 16 finished with value: 0.0428776 and parameters: {'lambda': 2.4412119454397883, 'alpha': 0.3484342647435423, 'max_depth': 8, 'eta': 0.2, 'gamma': 0.6742830694262545, 'grow_policy': 'depthwise', 'min_child_weight': 4, 'subsample': 0.828489693177779, 'colsample_bytree': 0.9679408356810948, 'max_delta_step': 5}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:03:33,583]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:03:35,363]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:03:37,798]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:03:39,516]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:03:45,333]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:03:51,175]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:03:59,415]\u001b[0m Trial 23 finished with value: 0.0427312 and parameters: {'lambda': 2.703131286274063, 'alpha': 0.25528721911111246, 'max_depth': 8, 'eta': 0.2, 'gamma': 1.574541850790826, 'grow_policy': 'depthwise', 'min_child_weight': 2, 'subsample': 0.8093166183177795, 'colsample_bytree': 0.9513801008412277, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:04:03,963]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 28.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:04:09,020]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 43.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:04:10,928]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:04:15,541]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 43.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:04:17,210]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:04:19,433]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:04:21,288]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:04:27,473]\u001b[0m Trial 31 finished with value: 0.0428148 and parameters: {'lambda': 2.8422729519243317, 'alpha': 0.4205002175876023, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.6352023400422562, 'grow_policy': 'depthwise', 'min_child_weight': 3, 'subsample': 0.8517096587250503, 'colsample_bytree': 0.9406784263189281, 'max_delta_step': 2}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:04:33,496]\u001b[0m Trial 32 finished with value: 0.04269860000000001 and parameters: {'lambda': 2.5267426955162926, 'alpha': 0.2067297419292088, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.260752711144645, 'grow_policy': 'depthwise', 'min_child_weight': 3, 'subsample': 0.8152044027075958, 'colsample_bytree': 0.9229375200887475, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:04:35,333]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:04:37,175]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:04:55,762]\u001b[0m Trial 35 finished with value: 0.042815000000000006 and parameters: {'lambda': 1.6625512370519857, 'alpha': 0.332377740751378, 'max_depth': 8, 'eta': 0.2, 'gamma': 2.0258782130706536, 'grow_policy': 'lossguide', 'min_child_weight': 2, 'subsample': 0.8952482202642116, 'colsample_bytree': 0.9199479082745649, 'max_delta_step': 3}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:04:57,468]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:05:02,789]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:05:06,356]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 35.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:05:12,491]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:05:14,420]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:05:16,289]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:05:21,263]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 42.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:05:27,383]\u001b[0m Trial 43 finished with value: 0.042788 and parameters: {'lambda': 2.8236188003248137, 'alpha': 0.5099357341384145, 'max_depth': 9, 'eta': 0.2, 'gamma': 0.8347520448603498, 'grow_policy': 'depthwise', 'min_child_weight': 2, 'subsample': 0.8279535813136347, 'colsample_bytree': 0.9457210123073905, 'max_delta_step': 2}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:05:33,707]\u001b[0m Trial 44 finished with value: 0.0427838 and parameters: {'lambda': 2.9838516941819, 'alpha': 0.23848322926039583, 'max_depth': 9, 'eta': 0.2, 'gamma': 0.7611927262824085, 'grow_policy': 'depthwise', 'min_child_weight': 2, 'subsample': 0.9087888365918554, 'colsample_bytree': 0.9490812438231304, 'max_delta_step': 3}. Best is trial 3 with value: 0.0424108.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-02 22:05:38,602]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:05:42,659]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 38.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:05:44,541]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:05:46,438]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:05:50,144]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 40.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:05:56,903]\u001b[0m Trial 50 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:02,651]\u001b[0m Trial 51 finished with value: 0.0427314 and parameters: {'lambda': 2.833936642268488, 'alpha': 0.2570879605588737, 'max_depth': 9, 'eta': 0.2, 'gamma': 0.8598969311610598, 'grow_policy': 'depthwise', 'min_child_weight': 2, 'subsample': 0.8254556532706808, 'colsample_bytree': 0.9458733489411156, 'max_delta_step': 2}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:08,817]\u001b[0m Trial 52 finished with value: 0.0426742 and parameters: {'lambda': 2.851758339611834, 'alpha': 0.2695140992702665, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.3026178050718873, 'grow_policy': 'depthwise', 'min_child_weight': 2, 'subsample': 0.8006124254867859, 'colsample_bytree': 0.9481732389483122, 'max_delta_step': 2}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:10,706]\u001b[0m Trial 53 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:12,419]\u001b[0m Trial 54 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:14,396]\u001b[0m Trial 55 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:15,996]\u001b[0m Trial 56 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:17,707]\u001b[0m Trial 57 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:19,724]\u001b[0m Trial 58 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:21,464]\u001b[0m Trial 59 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:25,351]\u001b[0m Trial 60 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:30,900]\u001b[0m Trial 61 pruned. Trial was pruned at iteration 48.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:34,162]\u001b[0m Trial 62 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:38,279]\u001b[0m Trial 63 pruned. Trial was pruned at iteration 35.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:40,189]\u001b[0m Trial 64 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:43,531]\u001b[0m Trial 65 pruned. Trial was pruned at iteration 32.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:45,463]\u001b[0m Trial 66 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:49,606]\u001b[0m Trial 67 pruned. Trial was pruned at iteration 32.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:51,362]\u001b[0m Trial 68 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:56,658]\u001b[0m Trial 69 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:06:58,639]\u001b[0m Trial 70 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:07:02,166]\u001b[0m Trial 71 pruned. Trial was pruned at iteration 22.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:07:07,260]\u001b[0m Trial 72 pruned. Trial was pruned at iteration 44.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:07:09,304]\u001b[0m Trial 73 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:07:11,251]\u001b[0m Trial 74 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:07:16,779]\u001b[0m Trial 75 pruned. Trial was pruned at iteration 45.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:07:18,987]\u001b[0m Trial 76 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:07:21,088]\u001b[0m Trial 77 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:07:23,119]\u001b[0m Trial 78 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:07:27,718]\u001b[0m Trial 79 pruned. Trial was pruned at iteration 40.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:07:38,894]\u001b[0m Trial 80 pruned. Trial was pruned at iteration 32.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:07:45,407]\u001b[0m Trial 81 finished with value: 0.042661 and parameters: {'lambda': 2.740690737394259, 'alpha': 0.45361704840395667, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.317180357479751, 'grow_policy': 'depthwise', 'min_child_weight': 3, 'subsample': 0.827580584801719, 'colsample_bytree': 0.9398034977825774, 'max_delta_step': 2}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:07:47,766]\u001b[0m Trial 82 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:07:49,565]\u001b[0m Trial 83 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:07:52,028]\u001b[0m Trial 84 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:07:54,056]\u001b[0m Trial 85 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:07:57,477]\u001b[0m Trial 86 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:07:59,271]\u001b[0m Trial 87 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:01,692]\u001b[0m Trial 88 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:03,436]\u001b[0m Trial 89 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:06,013]\u001b[0m Trial 90 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:10,323]\u001b[0m Trial 91 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:13,218]\u001b[0m Trial 92 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:15,168]\u001b[0m Trial 93 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:21,010]\u001b[0m Trial 94 pruned. Trial was pruned at iteration 36.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:23,118]\u001b[0m Trial 95 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:29,416]\u001b[0m Trial 96 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:31,337]\u001b[0m Trial 97 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:35,500]\u001b[0m Trial 98 pruned. Trial was pruned at iteration 34.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:38,104]\u001b[0m Trial 99 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:40,180]\u001b[0m Trial 100 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:42,739]\u001b[0m Trial 101 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:46,374]\u001b[0m Trial 102 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:48,404]\u001b[0m Trial 103 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:54,597]\u001b[0m Trial 104 finished with value: 0.042735 and parameters: {'lambda': 2.9537358099434763, 'alpha': 0.08862882327293786, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.4654540142903825, 'grow_policy': 'depthwise', 'min_child_weight': 2, 'subsample': 0.8227649273821745, 'colsample_bytree': 0.923569313946664, 'max_delta_step': 2}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:08:59,388]\u001b[0m Trial 105 pruned. Trial was pruned at iteration 42.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:09:01,747]\u001b[0m Trial 106 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:09:03,635]\u001b[0m Trial 107 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:09:05,549]\u001b[0m Trial 108 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:09:07,643]\u001b[0m Trial 109 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:09:09,229]\u001b[0m Trial 110 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:09:11,107]\u001b[0m Trial 111 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:09:16,645]\u001b[0m Trial 112 pruned. Trial was pruned at iteration 48.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:09:18,903]\u001b[0m Trial 113 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:09:21,160]\u001b[0m Trial 114 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:09:24,272]\u001b[0m Trial 115 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:09:26,426]\u001b[0m Trial 116 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:09:28,586]\u001b[0m Trial 117 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:09:32,843]\u001b[0m Trial 118 pruned. Trial was pruned at iteration 34.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:09:34,864]\u001b[0m Trial 119 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:09:36,902]\u001b[0m Trial 120 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-02 22:09:46,066]\u001b[0m Trial 121 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:09:51,407]\u001b[0m Trial 122 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:06,287]\u001b[0m Trial 123 pruned. Trial was pruned at iteration 27.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:10,791]\u001b[0m Trial 124 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:20,157]\u001b[0m Trial 125 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:24,393]\u001b[0m Trial 126 pruned. Trial was pruned at iteration 33.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:26,561]\u001b[0m Trial 127 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:31,159]\u001b[0m Trial 128 pruned. Trial was pruned at iteration 40.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:36,309]\u001b[0m Trial 129 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:38,073]\u001b[0m Trial 130 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:39,872]\u001b[0m Trial 131 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:41,655]\u001b[0m Trial 132 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:43,896]\u001b[0m Trial 133 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:45,774]\u001b[0m Trial 134 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:47,587]\u001b[0m Trial 135 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:49,256]\u001b[0m Trial 136 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:50,552]\u001b[0m Trial 137 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:52,435]\u001b[0m Trial 138 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:54,299]\u001b[0m Trial 139 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:10:57,987]\u001b[0m Trial 140 pruned. Trial was pruned at iteration 35.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:11:00,935]\u001b[0m Trial 141 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:11:03,950]\u001b[0m Trial 142 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:11:07,074]\u001b[0m Trial 143 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:11:13,329]\u001b[0m Trial 144 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:11:16,050]\u001b[0m Trial 145 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:11:17,665]\u001b[0m Trial 146 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:11:19,402]\u001b[0m Trial 147 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:11:22,308]\u001b[0m Trial 148 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:11:24,450]\u001b[0m Trial 149 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:11:26,875]\u001b[0m Trial 150 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:11:32,640]\u001b[0m Trial 151 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:11:39,342]\u001b[0m Trial 152 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:00,485]\u001b[0m Trial 153 pruned. Trial was pruned at iteration 34.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:04,656]\u001b[0m Trial 154 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:09,122]\u001b[0m Trial 155 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:15,560]\u001b[0m Trial 156 finished with value: 0.042706 and parameters: {'lambda': 2.1930554774390956, 'alpha': 0.28841015818661875, 'max_depth': 9, 'eta': 0.2, 'gamma': 0.6113751091196963, 'grow_policy': 'depthwise', 'min_child_weight': 3, 'subsample': 0.8154485072898651, 'colsample_bytree': 0.9507753732538764, 'max_delta_step': 3}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:19,539]\u001b[0m Trial 157 pruned. Trial was pruned at iteration 36.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:21,488]\u001b[0m Trial 158 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:26,275]\u001b[0m Trial 159 pruned. Trial was pruned at iteration 35.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:28,872]\u001b[0m Trial 160 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:32,227]\u001b[0m Trial 161 pruned. Trial was pruned at iteration 27.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:36,185]\u001b[0m Trial 162 pruned. Trial was pruned at iteration 32.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:38,066]\u001b[0m Trial 163 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:40,012]\u001b[0m Trial 164 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:42,162]\u001b[0m Trial 165 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:47,517]\u001b[0m Trial 166 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:49,609]\u001b[0m Trial 167 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:53,216]\u001b[0m Trial 168 pruned. Trial was pruned at iteration 36.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:55,094]\u001b[0m Trial 169 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:12:57,390]\u001b[0m Trial 170 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:13:07,187]\u001b[0m Trial 171 pruned. Trial was pruned at iteration 34.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:13:17,425]\u001b[0m Trial 172 pruned. Trial was pruned at iteration 35.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:13:27,141]\u001b[0m Trial 173 pruned. Trial was pruned at iteration 34.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:13:37,048]\u001b[0m Trial 174 pruned. Trial was pruned at iteration 33.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:13:42,025]\u001b[0m Trial 175 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:13:48,200]\u001b[0m Trial 176 finished with value: 0.0426794 and parameters: {'lambda': 2.7871955254296688, 'alpha': 0.22537802242543184, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.4030591107066166, 'grow_policy': 'depthwise', 'min_child_weight': 2, 'subsample': 0.93050818472383, 'colsample_bytree': 0.9484932249282002, 'max_delta_step': 2}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:13:51,784]\u001b[0m Trial 177 pruned. Trial was pruned at iteration 28.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:13:55,208]\u001b[0m Trial 178 pruned. Trial was pruned at iteration 27.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:00,301]\u001b[0m Trial 179 pruned. Trial was pruned at iteration 44.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:04,790]\u001b[0m Trial 180 pruned. Trial was pruned at iteration 42.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:06,783]\u001b[0m Trial 181 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:08,653]\u001b[0m Trial 182 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:10,314]\u001b[0m Trial 183 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:16,193]\u001b[0m Trial 184 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:17,934]\u001b[0m Trial 185 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:19,458]\u001b[0m Trial 186 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:23,185]\u001b[0m Trial 187 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:28,572]\u001b[0m Trial 188 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:30,257]\u001b[0m Trial 189 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:33,657]\u001b[0m Trial 190 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:37,501]\u001b[0m Trial 191 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:41,848]\u001b[0m Trial 192 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:44,531]\u001b[0m Trial 193 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:48,420]\u001b[0m Trial 194 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:53,460]\u001b[0m Trial 195 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:55,640]\u001b[0m Trial 196 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:57,935]\u001b[0m Trial 197 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:14:59,860]\u001b[0m Trial 198 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:15:07,602]\u001b[0m Trial 199 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:15:09,334]\u001b[0m Trial 200 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:15:11,551]\u001b[0m Trial 201 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:15:13,937]\u001b[0m Trial 202 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-02 22:15:18,863]\u001b[0m Trial 203 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:15:25,366]\u001b[0m Trial 204 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:15:27,063]\u001b[0m Trial 205 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:15:29,634]\u001b[0m Trial 206 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:15:31,304]\u001b[0m Trial 207 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:15:33,262]\u001b[0m Trial 208 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:15:35,252]\u001b[0m Trial 209 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:15:48,312]\u001b[0m Trial 210 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:15:50,321]\u001b[0m Trial 211 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:15:52,384]\u001b[0m Trial 212 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:15:55,607]\u001b[0m Trial 213 pruned. Trial was pruned at iteration 28.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:15:58,864]\u001b[0m Trial 214 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:16:00,851]\u001b[0m Trial 215 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:16:04,826]\u001b[0m Trial 216 pruned. Trial was pruned at iteration 38.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:16:08,713]\u001b[0m Trial 217 pruned. Trial was pruned at iteration 34.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:16:18,856]\u001b[0m Trial 218 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:16:21,019]\u001b[0m Trial 219 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:16:23,179]\u001b[0m Trial 220 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:16:25,378]\u001b[0m Trial 221 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:16:27,650]\u001b[0m Trial 222 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:16:30,366]\u001b[0m Trial 223 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:16:33,352]\u001b[0m Trial 224 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:16:35,582]\u001b[0m Trial 225 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:16:37,868]\u001b[0m Trial 226 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:16:42,548]\u001b[0m Trial 227 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:16:44,695]\u001b[0m Trial 228 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:16:47,433]\u001b[0m Trial 229 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:17:08,718]\u001b[0m Trial 230 finished with value: 0.042773 and parameters: {'lambda': 2.7151770979074814, 'alpha': 0.16245193834320562, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.441210417295369, 'grow_policy': 'lossguide', 'min_child_weight': 2, 'subsample': 0.8328898008508596, 'colsample_bytree': 0.9335358675163347, 'max_delta_step': 2}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:17:24,912]\u001b[0m Trial 231 pruned. Trial was pruned at iteration 32.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:17:36,500]\u001b[0m Trial 232 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:17:46,686]\u001b[0m Trial 233 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:17:52,965]\u001b[0m Trial 234 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:17:59,948]\u001b[0m Trial 235 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:18:03,610]\u001b[0m Trial 236 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:18:10,198]\u001b[0m Trial 237 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:18:12,164]\u001b[0m Trial 238 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:18:13,947]\u001b[0m Trial 239 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:18:20,082]\u001b[0m Trial 240 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:18:25,232]\u001b[0m Trial 241 pruned. Trial was pruned at iteration 45.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:18:30,452]\u001b[0m Trial 242 pruned. Trial was pruned at iteration 44.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:18:37,110]\u001b[0m Trial 243 finished with value: 0.042740999999999994 and parameters: {'lambda': 2.636831606311417, 'alpha': 0.5207076500779995, 'max_depth': 9, 'eta': 0.2, 'gamma': 0.2883044855823205, 'grow_policy': 'depthwise', 'min_child_weight': 2, 'subsample': 0.8368532619466403, 'colsample_bytree': 0.961228429299521, 'max_delta_step': 2}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:18:41,647]\u001b[0m Trial 244 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:18:47,826]\u001b[0m Trial 245 finished with value: 0.042649000000000006 and parameters: {'lambda': 2.6472168739512965, 'alpha': 0.43938634812809696, 'max_depth': 9, 'eta': 0.2, 'gamma': 0.37769253223059646, 'grow_policy': 'depthwise', 'min_child_weight': 2, 'subsample': 0.8368536736442537, 'colsample_bytree': 0.9764865413400745, 'max_delta_step': 2}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:18:49,501]\u001b[0m Trial 246 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:18:53,218]\u001b[0m Trial 247 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:18:56,594]\u001b[0m Trial 248 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:19:00,160]\u001b[0m Trial 249 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:19:02,229]\u001b[0m Trial 250 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:19:13,214]\u001b[0m Trial 251 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:19:15,437]\u001b[0m Trial 252 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:19:17,266]\u001b[0m Trial 253 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:19:23,138]\u001b[0m Trial 254 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:19:24,946]\u001b[0m Trial 255 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:19:28,037]\u001b[0m Trial 256 pruned. Trial was pruned at iteration 30.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:19:35,905]\u001b[0m Trial 257 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:19:37,676]\u001b[0m Trial 258 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:19:39,523]\u001b[0m Trial 259 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:19:43,468]\u001b[0m Trial 260 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:19:46,693]\u001b[0m Trial 261 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:19:48,913]\u001b[0m Trial 262 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:19:51,769]\u001b[0m Trial 263 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:20:02,151]\u001b[0m Trial 264 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:20:04,005]\u001b[0m Trial 265 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:20:06,080]\u001b[0m Trial 266 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:20:12,363]\u001b[0m Trial 267 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:20:14,496]\u001b[0m Trial 268 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:20:18,215]\u001b[0m Trial 269 pruned. Trial was pruned at iteration 27.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:20:21,251]\u001b[0m Trial 270 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:20:26,182]\u001b[0m Trial 271 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:20:27,940]\u001b[0m Trial 272 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:20:29,674]\u001b[0m Trial 273 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:20:35,678]\u001b[0m Trial 274 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:20:38,025]\u001b[0m Trial 275 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:20:39,515]\u001b[0m Trial 276 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:20:52,403]\u001b[0m Trial 277 pruned. Trial was pruned at iteration 22.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:20:55,773]\u001b[0m Trial 278 pruned. Trial was pruned at iteration 28.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:20:57,584]\u001b[0m Trial 279 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:20:59,427]\u001b[0m Trial 280 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-02 22:21:05,729]\u001b[0m Trial 281 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:21:07,631]\u001b[0m Trial 282 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:21:12,089]\u001b[0m Trial 283 pruned. Trial was pruned at iteration 39.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:21:19,038]\u001b[0m Trial 284 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:21:20,862]\u001b[0m Trial 285 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:21:22,583]\u001b[0m Trial 286 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:21:35,144]\u001b[0m Trial 287 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:21:37,166]\u001b[0m Trial 288 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:21:39,089]\u001b[0m Trial 289 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:21:42,988]\u001b[0m Trial 290 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:21:45,728]\u001b[0m Trial 291 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:21:49,272]\u001b[0m Trial 292 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:21:51,096]\u001b[0m Trial 293 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:21:55,500]\u001b[0m Trial 294 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:21:57,300]\u001b[0m Trial 295 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:00,644]\u001b[0m Trial 296 pruned. Trial was pruned at iteration 30.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:02,512]\u001b[0m Trial 297 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:05,095]\u001b[0m Trial 298 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:06,714]\u001b[0m Trial 299 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:15,117]\u001b[0m Trial 300 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:18,577]\u001b[0m Trial 301 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:20,609]\u001b[0m Trial 302 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:22,776]\u001b[0m Trial 303 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:27,237]\u001b[0m Trial 304 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:29,235]\u001b[0m Trial 305 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:31,117]\u001b[0m Trial 306 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:36,199]\u001b[0m Trial 307 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:37,881]\u001b[0m Trial 308 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:39,535]\u001b[0m Trial 309 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:43,122]\u001b[0m Trial 310 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:49,474]\u001b[0m Trial 311 finished with value: 0.04267339999999999 and parameters: {'lambda': 2.816228442217499, 'alpha': 0.2494281535089901, 'max_depth': 9, 'eta': 0.2, 'gamma': 0.9600551041048389, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.9750916644609823, 'colsample_bytree': 0.9322067473272959, 'max_delta_step': 2}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:53,498]\u001b[0m Trial 312 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:55,361]\u001b[0m Trial 313 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:22:59,480]\u001b[0m Trial 314 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:23:01,852]\u001b[0m Trial 315 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:23:05,752]\u001b[0m Trial 316 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:23:11,601]\u001b[0m Trial 317 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:23:13,915]\u001b[0m Trial 318 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:23:15,937]\u001b[0m Trial 319 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:23:21,468]\u001b[0m Trial 320 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:23:25,352]\u001b[0m Trial 321 pruned. Trial was pruned at iteration 29.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:23:27,457]\u001b[0m Trial 322 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:23:29,519]\u001b[0m Trial 323 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:23:31,520]\u001b[0m Trial 324 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:23:34,616]\u001b[0m Trial 325 pruned. Trial was pruned at iteration 30.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:23:40,108]\u001b[0m Trial 326 pruned. Trial was pruned at iteration 49.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:23:47,895]\u001b[0m Trial 327 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:23:49,617]\u001b[0m Trial 328 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:23:51,424]\u001b[0m Trial 329 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:23:56,751]\u001b[0m Trial 330 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:23:58,924]\u001b[0m Trial 331 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:24:00,860]\u001b[0m Trial 332 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:24:02,431]\u001b[0m Trial 333 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:24:07,233]\u001b[0m Trial 334 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:24:10,986]\u001b[0m Trial 335 pruned. Trial was pruned at iteration 29.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:24:12,653]\u001b[0m Trial 336 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:24:25,684]\u001b[0m Trial 337 pruned. Trial was pruned at iteration 32.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:24:27,322]\u001b[0m Trial 338 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:24:30,674]\u001b[0m Trial 339 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:24:32,491]\u001b[0m Trial 340 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:24:34,584]\u001b[0m Trial 341 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:24:36,728]\u001b[0m Trial 342 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:24:55,314]\u001b[0m Trial 343 pruned. Trial was pruned at iteration 44.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:24:57,225]\u001b[0m Trial 344 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:24:59,035]\u001b[0m Trial 345 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:25:02,942]\u001b[0m Trial 346 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:25:10,815]\u001b[0m Trial 347 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:25:12,775]\u001b[0m Trial 348 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:25:14,680]\u001b[0m Trial 349 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:25:24,230]\u001b[0m Trial 350 pruned. Trial was pruned at iteration 32.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:25:25,966]\u001b[0m Trial 351 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:25:27,743]\u001b[0m Trial 352 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:25:33,107]\u001b[0m Trial 353 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:25:34,964]\u001b[0m Trial 354 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:25:42,452]\u001b[0m Trial 355 finished with value: 0.0427218 and parameters: {'lambda': 2.943732393850574, 'alpha': 0.2925894515375371, 'max_depth': 9, 'eta': 0.2, 'gamma': 0.7631684128057372, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.829687459277451, 'colsample_bytree': 0.9405773087080176, 'max_delta_step': 2}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:25:46,351]\u001b[0m Trial 356 pruned. Trial was pruned at iteration 36.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:25:48,603]\u001b[0m Trial 357 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:25:50,616]\u001b[0m Trial 358 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:25:52,485]\u001b[0m Trial 359 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:25:54,421]\u001b[0m Trial 360 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:25:56,539]\u001b[0m Trial 361 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:26:03,617]\u001b[0m Trial 362 finished with value: 0.0427142 and parameters: {'lambda': 2.9752320749180967, 'alpha': 0.1484713304459207, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.0012663187067186, 'grow_policy': 'depthwise', 'min_child_weight': 2, 'subsample': 0.8192677031898693, 'colsample_bytree': 0.9470233641974273, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-02 22:26:07,153]\u001b[0m Trial 363 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:26:09,353]\u001b[0m Trial 364 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:26:15,935]\u001b[0m Trial 365 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:26:18,114]\u001b[0m Trial 366 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:26:20,414]\u001b[0m Trial 367 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:26:23,552]\u001b[0m Trial 368 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:26:26,388]\u001b[0m Trial 369 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:26:30,491]\u001b[0m Trial 370 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:26:32,602]\u001b[0m Trial 371 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:26:36,478]\u001b[0m Trial 372 pruned. Trial was pruned at iteration 30.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:26:38,623]\u001b[0m Trial 373 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:26:41,993]\u001b[0m Trial 374 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:26:45,285]\u001b[0m Trial 375 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:26:48,371]\u001b[0m Trial 376 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:26:53,470]\u001b[0m Trial 377 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:26:56,679]\u001b[0m Trial 378 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:00,117]\u001b[0m Trial 379 pruned. Trial was pruned at iteration 27.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:02,136]\u001b[0m Trial 380 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:03,670]\u001b[0m Trial 381 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:05,781]\u001b[0m Trial 382 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:08,907]\u001b[0m Trial 383 pruned. Trial was pruned at iteration 22.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:10,734]\u001b[0m Trial 384 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:14,439]\u001b[0m Trial 385 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:16,253]\u001b[0m Trial 386 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:18,104]\u001b[0m Trial 387 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:20,131]\u001b[0m Trial 388 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:22,028]\u001b[0m Trial 389 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:24,044]\u001b[0m Trial 390 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:26,201]\u001b[0m Trial 391 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:28,962]\u001b[0m Trial 392 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:31,164]\u001b[0m Trial 393 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:33,087]\u001b[0m Trial 394 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:35,334]\u001b[0m Trial 395 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:37,306]\u001b[0m Trial 396 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:40,881]\u001b[0m Trial 397 pruned. Trial was pruned at iteration 30.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:44,498]\u001b[0m Trial 398 pruned. Trial was pruned at iteration 29.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:46,329]\u001b[0m Trial 399 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:50,283]\u001b[0m Trial 400 pruned. Trial was pruned at iteration 28.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:53,591]\u001b[0m Trial 401 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:55,537]\u001b[0m Trial 402 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:27:58,796]\u001b[0m Trial 403 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:28:00,453]\u001b[0m Trial 404 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:28:02,177]\u001b[0m Trial 405 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:28:05,027]\u001b[0m Trial 406 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:28:07,193]\u001b[0m Trial 407 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:28:14,305]\u001b[0m Trial 408 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:28:16,489]\u001b[0m Trial 409 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:28:18,414]\u001b[0m Trial 410 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:28:21,911]\u001b[0m Trial 411 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:28:30,676]\u001b[0m Trial 412 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:28:33,016]\u001b[0m Trial 413 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:28:35,244]\u001b[0m Trial 414 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:28:39,274]\u001b[0m Trial 415 pruned. Trial was pruned at iteration 29.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:28:45,477]\u001b[0m Trial 416 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:28:47,308]\u001b[0m Trial 417 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:28:48,920]\u001b[0m Trial 418 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:28:51,983]\u001b[0m Trial 419 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:29:08,065]\u001b[0m Trial 420 pruned. Trial was pruned at iteration 32.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:29:10,256]\u001b[0m Trial 421 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:29:12,140]\u001b[0m Trial 422 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:29:16,074]\u001b[0m Trial 423 pruned. Trial was pruned at iteration 32.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:29:25,902]\u001b[0m Trial 424 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:29:28,001]\u001b[0m Trial 425 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:29:29,922]\u001b[0m Trial 426 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:29:31,940]\u001b[0m Trial 427 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:29:34,018]\u001b[0m Trial 428 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:29:59,194]\u001b[0m Trial 429 finished with value: 0.04261379999999999 and parameters: {'lambda': 2.996952083024672, 'alpha': 0.28530799381554683, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.3044021909100294, 'grow_policy': 'lossguide', 'min_child_weight': 1, 'subsample': 0.8222465940469856, 'colsample_bytree': 0.9419261551636046, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:30:16,312]\u001b[0m Trial 430 pruned. Trial was pruned at iteration 33.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:30:22,566]\u001b[0m Trial 431 finished with value: 0.0426636 and parameters: {'lambda': 2.944317636959099, 'alpha': 0.34170405570078416, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.1533639784404752, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.8215158205715342, 'colsample_bytree': 0.9371387916073847, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:30:29,865]\u001b[0m Trial 432 finished with value: 0.0426474 and parameters: {'lambda': 2.9729874958371716, 'alpha': 0.3590185642180698, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.0797219619514997, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.8220561321245825, 'colsample_bytree': 0.937420412190859, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:30:36,324]\u001b[0m Trial 433 finished with value: 0.04271 and parameters: {'lambda': 2.988467226784819, 'alpha': 0.3637999536817817, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.0999373671475912, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.8190316796002494, 'colsample_bytree': 0.9372221117167309, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:30:39,912]\u001b[0m Trial 434 pruned. Trial was pruned at iteration 27.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:30:45,078]\u001b[0m Trial 435 pruned. Trial was pruned at iteration 52.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:30:49,000]\u001b[0m Trial 436 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:30:55,102]\u001b[0m Trial 437 finished with value: 0.0426098 and parameters: {'lambda': 2.984527298697341, 'alpha': 0.3353757357688171, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.1771721701890399, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.82120782923434, 'colsample_bytree': 0.9387428259307514, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-02 22:31:01,397]\u001b[0m Trial 438 finished with value: 0.0426028 and parameters: {'lambda': 2.9874551404626355, 'alpha': 0.31584457698547014, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.1739368294449886, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.8187497841774649, 'colsample_bytree': 0.9371791403641716, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:31:05,415]\u001b[0m Trial 439 pruned. Trial was pruned at iteration 37.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:31:09,243]\u001b[0m Trial 440 pruned. Trial was pruned at iteration 32.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:31:13,197]\u001b[0m Trial 441 pruned. Trial was pruned at iteration 35.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:31:17,202]\u001b[0m Trial 442 pruned. Trial was pruned at iteration 34.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:31:19,739]\u001b[0m Trial 443 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:31:21,789]\u001b[0m Trial 444 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:31:25,414]\u001b[0m Trial 445 pruned. Trial was pruned at iteration 30.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:31:28,876]\u001b[0m Trial 446 pruned. Trial was pruned at iteration 27.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:31:34,473]\u001b[0m Trial 447 finished with value: 0.042673800000000005 and parameters: {'lambda': 2.9333414377099647, 'alpha': 0.32889303056710906, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.1845703443810067, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.819623864661795, 'colsample_bytree': 0.936296007220446, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:31:40,320]\u001b[0m Trial 448 finished with value: 0.0424712 and parameters: {'lambda': 2.9439831465762727, 'alpha': 0.33578456801134055, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.1837809823190937, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.8185947459293994, 'colsample_bytree': 0.937046376113264, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:31:42,253]\u001b[0m Trial 449 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:31:45,102]\u001b[0m Trial 450 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:31:47,144]\u001b[0m Trial 451 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:31:50,414]\u001b[0m Trial 452 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:31:57,099]\u001b[0m Trial 453 finished with value: 0.0425976 and parameters: {'lambda': 2.9162062489991407, 'alpha': 0.32550784021858775, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.1767499430311148, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.80730314131297, 'colsample_bytree': 0.9339456792883776, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:00,884]\u001b[0m Trial 454 pruned. Trial was pruned at iteration 35.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:03,650]\u001b[0m Trial 455 pruned. Trial was pruned at iteration 22.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:06,701]\u001b[0m Trial 456 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:09,798]\u001b[0m Trial 457 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:12,846]\u001b[0m Trial 458 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:19,765]\u001b[0m Trial 459 finished with value: 0.042689599999999994 and parameters: {'lambda': 2.8888443864829956, 'alpha': 0.27687801236966586, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.1245584206740658, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.8179049849228169, 'colsample_bytree': 0.9373155269579706, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:22,739]\u001b[0m Trial 460 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:27,288]\u001b[0m Trial 461 pruned. Trial was pruned at iteration 43.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:33,686]\u001b[0m Trial 462 finished with value: 0.0426622 and parameters: {'lambda': 2.902944293206476, 'alpha': 0.3792067611590432, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.1755875403730367, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.8059949664032352, 'colsample_bytree': 0.9295355405395473, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:37,006]\u001b[0m Trial 463 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:39,485]\u001b[0m Trial 464 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:43,032]\u001b[0m Trial 465 pruned. Trial was pruned at iteration 28.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:45,920]\u001b[0m Trial 466 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:48,739]\u001b[0m Trial 467 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:51,393]\u001b[0m Trial 468 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:53,608]\u001b[0m Trial 469 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:56,053]\u001b[0m Trial 470 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:32:59,179]\u001b[0m Trial 471 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:33:05,489]\u001b[0m Trial 472 pruned. Trial was pruned at iteration 44.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:33:11,537]\u001b[0m Trial 473 finished with value: 0.0425482 and parameters: {'lambda': 2.8926816402676963, 'alpha': 0.3183479300209243, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.0549792245836167, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.818192319430614, 'colsample_bytree': 0.9443893644300603, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:33:15,011]\u001b[0m Trial 474 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:33:18,651]\u001b[0m Trial 475 pruned. Trial was pruned at iteration 27.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:33:21,895]\u001b[0m Trial 476 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:33:28,727]\u001b[0m Trial 477 finished with value: 0.042574999999999995 and parameters: {'lambda': 2.8958540971575064, 'alpha': 0.2959618412440736, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.183583053601146, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.8199954306423677, 'colsample_bytree': 0.9366028237748069, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:33:30,795]\u001b[0m Trial 478 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:33:36,803]\u001b[0m Trial 479 finished with value: 0.0426576 and parameters: {'lambda': 2.920131508321728, 'alpha': 0.3905279443540238, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.1673269645601285, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.8200670122051434, 'colsample_bytree': 0.9325222784661092, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:33:38,850]\u001b[0m Trial 480 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:33:40,808]\u001b[0m Trial 481 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:33:46,935]\u001b[0m Trial 482 finished with value: 0.042620399999999996 and parameters: {'lambda': 2.9247318862227325, 'alpha': 0.3570726458119522, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.2501711757188025, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.8188097309188112, 'colsample_bytree': 0.9369410133812521, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:33:48,862]\u001b[0m Trial 483 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:33:52,525]\u001b[0m Trial 484 pruned. Trial was pruned at iteration 33.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:33:54,628]\u001b[0m Trial 485 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:34:01,533]\u001b[0m Trial 486 finished with value: 0.0427022 and parameters: {'lambda': 2.904768733403644, 'alpha': 0.39945668799638556, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.2231848258948206, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.820560202079222, 'colsample_bytree': 0.938516411344767, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:34:04,894]\u001b[0m Trial 487 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:34:07,908]\u001b[0m Trial 488 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:34:13,129]\u001b[0m Trial 489 finished with value: 0.042657799999999996 and parameters: {'lambda': 2.8337243733296384, 'alpha': 0.4395900136442415, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.2027956384478118, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.820151406007681, 'colsample_bytree': 0.932229754339792, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-02 22:34:15,032]\u001b[0m Trial 490 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:34:17,287]\u001b[0m Trial 491 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:34:19,344]\u001b[0m Trial 492 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:34:24,900]\u001b[0m Trial 493 pruned. Trial was pruned at iteration 36.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:34:27,224]\u001b[0m Trial 494 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:34:29,340]\u001b[0m Trial 495 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:34:31,519]\u001b[0m Trial 496 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:34:37,901]\u001b[0m Trial 497 finished with value: 0.04254 and parameters: {'lambda': 2.8099764439521437, 'alpha': 0.3900092903899828, 'max_depth': 9, 'eta': 0.2, 'gamma': 1.1567621970055249, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'subsample': 0.8085057720887568, 'colsample_bytree': 0.9388749550964745, 'max_delta_step': 4}. Best is trial 3 with value: 0.0424108.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:34:40,046]\u001b[0m Trial 498 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 22:34:42,479]\u001b[0m Trial 499 pruned. Trial was pruned at iteration 12.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "    study = optuna.create_study(pruner=pruner, direction='minimize')\n",
    "    study.optimize(objective, \n",
    "                   #n_trials=50\n",
    "                   n_trials=500\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-25T04:11:59.726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 500\n",
      "Best trial:\n",
      "  Value: 0.0424108\n",
      "  Params: \n",
      "    lambda: 1.2413359401393276\n",
      "    alpha: 0.16326090314688657\n",
      "    max_depth: 8\n",
      "    eta: 0.1\n",
      "    gamma: 1.1868232671204701\n",
      "    grow_policy: depthwise\n",
      "    min_child_weight: 4\n",
      "    subsample: 0.8780950055491423\n",
      "    colsample_bytree: 0.9241363413993084\n",
      "    max_delta_step: 3\n"
     ]
    }
   ],
   "source": [
    "print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('  Value: {}'.format(trial.value))\n",
    "\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_trials=50\n",
    "\n",
    "Params: \n",
    "    lambda: 2.652579588756935\n",
    "    alpha: 1.4208405720586856\n",
    "    max_depth: 8\n",
    "    eta: 0.3\n",
    "    gamma: 1.0809389255690658\n",
    "    grow_policy: lossguide\n",
    "    min_child_weight: 2\n",
    "    subsample: 0.9033901196294835\n",
    "    colsample_bytree: 0.8010648180780473\n",
    "    max_delta_step: 8\n",
    "   \n",
    "   \n",
    "#### n_trials=500\n",
    "Params: \n",
    "    lambda: 0.8545938248212175\n",
    "    alpha: 0.4512391408998466\n",
    "    max_depth: 8\n",
    "    eta: 0.1\n",
    "    gamma: 0.2038341012648358\n",
    "    grow_policy: depthwise\n",
    "    min_child_weight: 1\n",
    "    subsample: 0.9094012577087329\n",
    "    colsample_bytree: 0.8079200202937279\n",
    "    max_delta_step: 2\n",
    "    \n",
    "    \n",
    "#### n_trials=500, test3\n",
    "Params: \n",
    "    lambda: 2.013028734650969\n",
    "    alpha: 0.7436089160412054\n",
    "    max_depth: 7\n",
    "    eta: 0.1\n",
    "    gamma: 0.1781704703152439\n",
    "    grow_policy: depthwise\n",
    "    min_child_weight: 1\n",
    "    subsample: 0.820997112976606\n",
    "    colsample_bytree: 0.9745950996848067\n",
    "    max_delta_step: 3\n",
    "    \n",
    "    \n",
    "#### n_trials=500, test4\n",
    "Params: \n",
    "    lambda: 1.4203472995540372\n",
    "    alpha: 1.6997113468066785\n",
    "    max_depth: 9\n",
    "    eta: 0.2\n",
    "    gamma: 0.79634077651323\n",
    "    grow_policy: depthwise\n",
    "    min_child_weight: 3\n",
    "    subsample: 0.908673742111451\n",
    "    colsample_bytree: 0.9750229974864385\n",
    "    max_delta_step: 5\n",
    "\n",
    "#### n_trials=500 test5\n",
    "Params: \n",
    "    lambda: 1.2413359401393276\n",
    "    alpha: 0.16326090314688657\n",
    "    max_depth: 8\n",
    "    eta: 0.1\n",
    "    gamma: 1.1868232671204701\n",
    "    grow_policy: depthwise\n",
    "    min_child_weight: 4\n",
    "    subsample: 0.8780950055491423\n",
    "    colsample_bytree: 0.9241363413993084\n",
    "    max_delta_step: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-25T04:12:00.101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_alpha</th>\n",
       "      <th>params_colsample_bytree</th>\n",
       "      <th>params_eta</th>\n",
       "      <th>params_gamma</th>\n",
       "      <th>params_grow_policy</th>\n",
       "      <th>params_lambda</th>\n",
       "      <th>params_max_delta_step</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_child_weight</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.042894</td>\n",
       "      <td>2023-05-02 22:01:12.268272</td>\n",
       "      <td>2023-05-02 22:01:29.953150</td>\n",
       "      <td>0 days 00:00:17.684878</td>\n",
       "      <td>0.775410</td>\n",
       "      <td>0.873944</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.838087</td>\n",
       "      <td>lossguide</td>\n",
       "      <td>2.129023</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.954273</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.042928</td>\n",
       "      <td>2023-05-02 22:01:29.965689</td>\n",
       "      <td>2023-05-02 22:01:54.789103</td>\n",
       "      <td>0 days 00:00:24.823414</td>\n",
       "      <td>0.088565</td>\n",
       "      <td>0.833855</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.490360</td>\n",
       "      <td>lossguide</td>\n",
       "      <td>1.570325</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947035</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.234230</td>\n",
       "      <td>2023-05-02 22:01:54.801161</td>\n",
       "      <td>2023-05-02 22:02:19.943776</td>\n",
       "      <td>0 days 00:00:25.142615</td>\n",
       "      <td>1.248677</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.258070</td>\n",
       "      <td>lossguide</td>\n",
       "      <td>1.395564</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.977190</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.042411</td>\n",
       "      <td>2023-05-02 22:02:19.953053</td>\n",
       "      <td>2023-05-02 22:02:27.667210</td>\n",
       "      <td>0 days 00:00:07.714157</td>\n",
       "      <td>0.163261</td>\n",
       "      <td>0.924136</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.186823</td>\n",
       "      <td>depthwise</td>\n",
       "      <td>1.241336</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.878095</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.043318</td>\n",
       "      <td>2023-05-02 22:02:27.678245</td>\n",
       "      <td>2023-05-02 22:02:37.806582</td>\n",
       "      <td>0 days 00:00:10.128337</td>\n",
       "      <td>0.158091</td>\n",
       "      <td>0.890529</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.885271</td>\n",
       "      <td>lossguide</td>\n",
       "      <td>1.528537</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.977175</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>0.090542</td>\n",
       "      <td>2023-05-02 22:34:27.230714</td>\n",
       "      <td>2023-05-02 22:34:29.340239</td>\n",
       "      <td>0 days 00:00:02.109525</td>\n",
       "      <td>0.434947</td>\n",
       "      <td>0.938860</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.183211</td>\n",
       "      <td>depthwise</td>\n",
       "      <td>2.862477</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.824971</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>0.090535</td>\n",
       "      <td>2023-05-02 22:34:29.346444</td>\n",
       "      <td>2023-05-02 22:34:31.519644</td>\n",
       "      <td>0 days 00:00:02.173200</td>\n",
       "      <td>0.329799</td>\n",
       "      <td>0.934419</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.248255</td>\n",
       "      <td>depthwise</td>\n",
       "      <td>2.904723</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.805107</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>0.042540</td>\n",
       "      <td>2023-05-02 22:34:31.525711</td>\n",
       "      <td>2023-05-02 22:34:37.900280</td>\n",
       "      <td>0 days 00:00:06.374569</td>\n",
       "      <td>0.390009</td>\n",
       "      <td>0.938875</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.156762</td>\n",
       "      <td>depthwise</td>\n",
       "      <td>2.809976</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808506</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>0.090537</td>\n",
       "      <td>2023-05-02 22:34:37.915485</td>\n",
       "      <td>2023-05-02 22:34:40.046048</td>\n",
       "      <td>0 days 00:00:02.130563</td>\n",
       "      <td>0.447858</td>\n",
       "      <td>0.937877</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.147958</td>\n",
       "      <td>depthwise</td>\n",
       "      <td>2.830302</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.807937</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>0.073770</td>\n",
       "      <td>2023-05-02 22:34:40.052203</td>\n",
       "      <td>2023-05-02 22:34:42.479616</td>\n",
       "      <td>0 days 00:00:02.427413</td>\n",
       "      <td>0.398983</td>\n",
       "      <td>0.933661</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.200861</td>\n",
       "      <td>depthwise</td>\n",
       "      <td>2.845969</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.809856</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     number     value             datetime_start          datetime_complete  \\\n",
       "0         0  0.042894 2023-05-02 22:01:12.268272 2023-05-02 22:01:29.953150   \n",
       "1         1  0.042928 2023-05-02 22:01:29.965689 2023-05-02 22:01:54.789103   \n",
       "2         2  0.234230 2023-05-02 22:01:54.801161 2023-05-02 22:02:19.943776   \n",
       "3         3  0.042411 2023-05-02 22:02:19.953053 2023-05-02 22:02:27.667210   \n",
       "4         4  0.043318 2023-05-02 22:02:27.678245 2023-05-02 22:02:37.806582   \n",
       "..      ...       ...                        ...                        ...   \n",
       "495     495  0.090542 2023-05-02 22:34:27.230714 2023-05-02 22:34:29.340239   \n",
       "496     496  0.090535 2023-05-02 22:34:29.346444 2023-05-02 22:34:31.519644   \n",
       "497     497  0.042540 2023-05-02 22:34:31.525711 2023-05-02 22:34:37.900280   \n",
       "498     498  0.090537 2023-05-02 22:34:37.915485 2023-05-02 22:34:40.046048   \n",
       "499     499  0.073770 2023-05-02 22:34:40.052203 2023-05-02 22:34:42.479616   \n",
       "\n",
       "                  duration  params_alpha  params_colsample_bytree  params_eta  \\\n",
       "0   0 days 00:00:17.684878      0.775410                 0.873944        0.10   \n",
       "1   0 days 00:00:24.823414      0.088565                 0.833855        0.20   \n",
       "2   0 days 00:00:25.142615      1.248677                 0.902500        0.01   \n",
       "3   0 days 00:00:07.714157      0.163261                 0.924136        0.10   \n",
       "4   0 days 00:00:10.128337      0.158091                 0.890529        0.30   \n",
       "..                     ...           ...                      ...         ...   \n",
       "495 0 days 00:00:02.109525      0.434947                 0.938860        0.20   \n",
       "496 0 days 00:00:02.173200      0.329799                 0.934419        0.20   \n",
       "497 0 days 00:00:06.374569      0.390009                 0.938875        0.20   \n",
       "498 0 days 00:00:02.130563      0.447858                 0.937877        0.20   \n",
       "499 0 days 00:00:02.427413      0.398983                 0.933661        0.20   \n",
       "\n",
       "     params_gamma params_grow_policy  params_lambda  params_max_delta_step  \\\n",
       "0        0.838087          lossguide       2.129023                      4   \n",
       "1        0.490360          lossguide       1.570325                      1   \n",
       "2        0.258070          lossguide       1.395564                      3   \n",
       "3        1.186823          depthwise       1.241336                      3   \n",
       "4        2.885271          lossguide       1.528537                      6   \n",
       "..            ...                ...            ...                    ...   \n",
       "495      1.183211          depthwise       2.862477                      4   \n",
       "496      1.248255          depthwise       2.904723                      4   \n",
       "497      1.156762          depthwise       2.809976                      4   \n",
       "498      1.147958          depthwise       2.830302                      4   \n",
       "499      1.200861          depthwise       2.845969                      4   \n",
       "\n",
       "     params_max_depth  params_min_child_weight  params_subsample     state  \n",
       "0                   6                        3          0.954273  COMPLETE  \n",
       "1                   8                        1          0.947035  COMPLETE  \n",
       "2                   7                        5          0.977190  COMPLETE  \n",
       "3                   8                        4          0.878095  COMPLETE  \n",
       "4                   8                        4          0.977175  COMPLETE  \n",
       "..                ...                      ...               ...       ...  \n",
       "495                 9                        1          0.824971    PRUNED  \n",
       "496                 9                        1          0.805107    PRUNED  \n",
       "497                 9                        1          0.808506  COMPLETE  \n",
       "498                 9                        1          0.807937    PRUNED  \n",
       "499                 9                        1          0.809856    PRUNED  \n",
       "\n",
       "[500 rows x 16 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-25T04:12:00.645Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=3, values=[0.0424108], datetime_start=datetime.datetime(2023, 5, 2, 22, 2, 19, 953053), datetime_complete=datetime.datetime(2023, 5, 2, 22, 2, 27, 667210), params={'lambda': 1.2413359401393276, 'alpha': 0.16326090314688657, 'max_depth': 8, 'eta': 0.1, 'gamma': 1.1868232671204701, 'grow_policy': 'depthwise', 'min_child_weight': 4, 'subsample': 0.8780950055491423, 'colsample_bytree': 0.9241363413993084, 'max_delta_step': 3}, distributions={'lambda': UniformDistribution(high=3.0, low=0.5), 'alpha': UniformDistribution(high=2.0, low=0.0), 'max_depth': IntUniformDistribution(high=9, low=3, step=1), 'eta': CategoricalDistribution(choices=(0.01, 0.1, 0.2, 0.3)), 'gamma': UniformDistribution(high=3.0, low=0.0), 'grow_policy': CategoricalDistribution(choices=('depthwise', 'lossguide')), 'min_child_weight': IntUniformDistribution(high=5, low=1, step=1), 'subsample': UniformDistribution(high=1.0, low=0.8), 'colsample_bytree': UniformDistribution(high=1.0, low=0.8), 'max_delta_step': IntUniformDistribution(high=8, low=1, step=1)}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.6031082000000001, 1: 0.5292724000000001, 2: 0.46768839999999995, 3: 0.415651, 4: 0.37121020000000005, 5: 0.3329766, 6: 0.30475399999999997, 7: 0.27528980000000003, 8: 0.24955660000000002, 9: 0.226895, 10: 0.20691739999999997, 11: 0.189268, 12: 0.1736534, 13: 0.1599084, 14: 0.1475786, 15: 0.138392, 16: 0.1283848, 17: 0.1194454, 18: 0.11151359999999999, 19: 0.10439260000000002, 20: 0.09803680000000001, 21: 0.09233620000000001, 22: 0.08816099999999999, 23: 0.08347639999999999, 24: 0.0792912, 25: 0.07555320000000001, 26: 0.07218240000000001, 27: 0.06915679999999999, 28: 0.0664668, 29: 0.0640858, 30: 0.06189600000000001, 31: 0.0599176, 32: 0.058157799999999996, 33: 0.056591999999999996, 34: 0.055167200000000007, 35: 0.0539126, 36: 0.052785399999999996, 37: 0.05179160000000001, 38: 0.05088659999999999, 39: 0.050076600000000006, 40: 0.049364200000000004, 41: 0.048696199999999995, 42: 0.0481134, 43: 0.047575799999999994, 44: 0.0471028, 45: 0.0466602, 46: 0.046291000000000006, 47: 0.0459152, 48: 0.0456118, 49: 0.0453316, 50: 0.0450716, 51: 0.0448584, 52: 0.044684, 53: 0.0445174, 54: 0.0443526, 55: 0.044186199999999995, 56: 0.044078599999999996, 57: 0.043957, 58: 0.0438422, 59: 0.0437588, 60: 0.0436638, 61: 0.043573600000000004, 62: 0.0435032, 63: 0.043431399999999995, 64: 0.04337200000000001, 65: 0.0433262, 66: 0.043281, 67: 0.043227, 68: 0.04318760000000001, 69: 0.04315479999999999, 70: 0.043117, 71: 0.04306, 72: 0.0430238, 73: 0.042989999999999993, 74: 0.042970400000000006, 75: 0.0429336, 76: 0.0429, 77: 0.0428732, 78: 0.0428348, 79: 0.0428044, 80: 0.042784, 81: 0.0427582, 82: 0.0427288, 83: 0.042712999999999994, 84: 0.042686, 85: 0.04265480000000001, 86: 0.0426488, 87: 0.0426318, 88: 0.042600200000000005, 89: 0.0425718, 90: 0.0425586, 91: 0.042548199999999994, 92: 0.0425316, 93: 0.042512799999999996, 94: 0.0424972, 95: 0.0424926, 96: 0.0424568, 97: 0.0424454, 98: 0.042430199999999994, 99: 0.0424108}, trial_id=3, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-25T04:12:11.332Z"
    }
   },
   "outputs": [],
   "source": [
    "opdf = study.trials_dataframe()\n",
    "from pathlib import Path\n",
    "Path(\"param_tune_records\").mkdir(exist_ok=True)\n",
    "opdf.to_pickle(\"param_tune_records/optuna_xgb_qso_vs_gal_cv-logloss-500trials-5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
